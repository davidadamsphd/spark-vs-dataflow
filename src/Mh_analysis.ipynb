{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CTRL_ID = 101 # Control experiment id\n",
    "TREAT_ID = 102  # Treatment experiment id\n",
    "LE_MEAN_ASP_CTRL = 1.0 # Low-end products average sale price (asp) (in Control)\n",
    "LE_MEAN_ASP_TREAT = 0.9 # Low-end products average sale price (asp) (in Treatment)\n",
    "HE_MEAN_ASP_CTRL = 2 # High-end products average sale price (asp) (in Control)\n",
    "HE_MEAN_ASP_TREAT = 2.2 # High-end product average sale price (asp) (in Treatment)\n",
    "    \n",
    "NUM_LE = 10 # Number of low-end products\n",
    "NUM_HE = 12 # Number of high-end products\n",
    "MEAN_LE_BIDS_MADE_CTRL = 5 # Averge number of bids made for low-end products (in Control)\n",
    "MEAN_HE_BIDS_MADE_CTRL = 20 # Averge number of bids made for high-end products (in Control)\n",
    "MEAN_LE_BIDS_MADE_TREAT = 8 # Averge number of bids made for low-end products (in Treatment)\n",
    "MEAN_HE_BIDS_MADE_TREAT = 24 # Averge number of bids made for high-end products (in Treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "Creating fake data\n",
    "\n",
    "Letâ€™s make two categories of products: low-end and high-end and have 100 in each category.\n",
    "Each product will have a different average sale count (sampled from a Beta Distribution:\n",
    "say Beta(3,15) -- mean of ~0.167 for both control and treatment\n",
    "\n",
    "The average sale price (asp) for are Normally distributed N(1, 0.2), N(2, 0.2), N(0.9, 0.2), N(2.2, 0.2)\n",
    "for sa-control, la-control, sa-treat, la-treat, respectively\n",
    "First, get the total number of simulated impressions per product: sample poission(\\lambda)\n",
    "'''\n",
    "np.random.seed(141592)\n",
    "\n",
    "def calc_sim_data(exp_id, product_ids, bids_won, bids_made, mean_asp, size):\n",
    "    exp_ids = exp_id*(np.ones(size))\n",
    "    bids = np.random.poisson(bids_made, size)\n",
    "    zeros = 0.0*(np.ones(size))\n",
    "    ones = np.ones(size)\n",
    "    data = np.concatenate(([exp_ids], [product_ids], [zeros], [bids_won]), axis=0).transpose()\n",
    "    full_data = np.repeat(data,bids, axis=0)\n",
    "\n",
    "    np.set_printoptions(suppress=True) # Suppress scientific notation.\n",
    "    for r in full_data:\n",
    "        r[2] = np.random.normal(mean_asp, 0.2)\n",
    "        r[3] = np.random.binomial(1, r[3])\n",
    "    return full_data\n",
    "    \n",
    "CTRL_ID = 101\n",
    "EXP_ID = 102\n",
    "LE_MEAN_ASP_CTRL = 1.0\n",
    "LE_MEAN_ASP_TREAT = 0.9\n",
    "HE_MEAN_ASP_CTRL = 2\n",
    "HE_MEAN_ASP_TREAT = 2.2\n",
    "\n",
    "NUM_LE = 10\n",
    "NUM_HE = 12\n",
    "MEAN_LE_BIDS_MADE_CTRL = 5\n",
    "MEAN_HE_BIDS_MADE_CTRL = 20\n",
    "MEAN_LE_BIDS_MADE_TREAT = 8\n",
    "MEAN_HE_BIDS_MADE_TREAT = 24\n",
    "\n",
    "le_product_ids = np.arange(1000,1000+NUM_LE)\n",
    "he_product_ids = np.arange(10000,10000+NUM_HE)\n",
    "\n",
    "le_bids_won = np.random.beta(3, 15, NUM_LE)\n",
    "he_bids_won = np.random.beta(3, 15, NUM_HE)\n",
    "\n",
    "le_data_ctrl = calc_sim_data(CTRL_ID, le_product_ids, le_bids_won, MEAN_LE_BIDS_MADE_CTRL, LE_MEAN_ASP_CTRL, NUM_LE)\n",
    "le_data_treat = calc_sim_data(TREAT_ID, le_product_ids, le_bids_won, MEAN_LE_BIDS_MADE_TREAT, LE_MEAN_ASP_TREAT, NUM_LE)\n",
    "he_data_ctrl = calc_sim_data(CTRL_ID, he_product_ids, he_bids_won, MEAN_HE_BIDS_MADE_CTRL, HE_MEAN_ASP_CTRL, NUM_HE)\n",
    "he_data_treat = calc_sim_data(TREAT_ID, he_product_ids, he_bids_won, MEAN_HE_BIDS_MADE_TREAT, HE_MEAN_ASP_TREAT, NUM_HE)\n",
    "\n",
    "all_data = np.concatenate(([le_data_ctrl], [le_data_treat],\n",
    "                          [he_data_ctrl], [he_data_treat]), axis=1)[0]\n",
    "np.set_printoptions(suppress=True)\n",
    "np.savetxt('sim_data_{0}_{1}.csv'.format(NUM_LE, NUM_HE), all_data, fmt='%i,%i,%5.2f,%i',\n",
    "           header=\"exp_id,product_id,price,sale_count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/davidada/apps/spark-2.0.0-bin-hadoop2.7\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.0.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.10 (default, Oct 23 2015 19:19:21)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "print(spark_home)\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.8.2.1-src.zip')) # for Spark 1.4\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.1-src.zip')) # for Spark 2.0\n",
    "\n",
    "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the numerator:\n",
    "# sum_i price_{ctrl_id,i} * sale_count_{treat_id,i} * w_i\n",
    "# and the denominator:\n",
    "# sum_i price_{treat_id,i} * sale_count_{ctrl_id,i} * w_i\n",
    "# where w_i = 1/(sale_count_{ctrl_id,i} + sale_count_{treat_id,i})\n",
    "def get_ctrl_treat(product_data):\n",
    "    # The shape is (product_id, iterable(id, price, sale_count))\n",
    "    r = list(product_data[1])\n",
    "    exp_idx = 0\n",
    "    assert len(r) == 2\n",
    "    if int(r[0][exp_idx]) == CTRL_ID and int(r[1][exp_idx]) == TREAT_ID:\n",
    "        ctrl = r[0]\n",
    "        treat = r[1]\n",
    "    elif int(r[1][exp_idx]) == CTRL_ID and int(r[0][exp_idx]) == TREAT_ID:\n",
    "        ctrl = r[1]\n",
    "        treat = r[0]\n",
    "    else:\n",
    "        assert False\n",
    "    return ctrl, treat\n",
    "\n",
    "\n",
    "def calc_numerator(product_data):\n",
    "    (price_idx, sale_count_idx) = (1, 2)\n",
    "    [ctrl, treat] = get_ctrl_treat(product_data)\n",
    "    w_inverse = (ctrl[sale_count_idx] + treat[sale_count_idx])\n",
    "    if w_inverse > 0:\n",
    "        return (treat[price_idx] * ctrl[sale_count_idx]) / w_inverse\n",
    "    else:\n",
    "        return 0\n",
    "            \n",
    "def calc_denominator(product_data):\n",
    "    (price_idx, sale_count_idx) = (1, 2)\n",
    "    [ctrl, treat] = get_ctrl_treat(product_data)\n",
    "    w_inverse = (ctrl[sale_count_idx] + treat[sale_count_idx])\n",
    "    if w_inverse > 0:\n",
    "        return (ctrl[price_idx] * treat[sale_count_idx]) / w_inverse\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "(exp, prod, price, sale_count) = (0,1,2,3)\n",
    "def convert_line(l):\n",
    "    return [int(l[exp]), int(l[prod]), float(l[price]), int(l[sale_count])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53.59940817352582, 47.42074413739855, 1.1302945398373545)\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "# We want to calculate MH(v_{t,i},n_{t,i},v_{c,i},n_{c,i}), where t and c are treatment and control\n",
    "# and there v and n in our cases are value of the sale prices and sale_count.\n",
    "input_rdd = sc.textFile('sim_data_{0}_{1}.csv'.format(NUM_LE, NUM_HE))\n",
    "header = input_rdd.first() # Remove the first line.\n",
    "parsed_input_rdd = input_rdd.filter(lambda x: x !=header).map(lambda x: convert_line(x.split(',')))\n",
    "transformed = parsed_input_rdd.map(lambda x: ((x[exp], x[prod]), (x[sale_count]*x[price], x[sale_count])))\n",
    "(sp, clks) = (0, 1) # sale price and sale_count\n",
    "(ep, spc) = (0, 1) # exp_id&product_id, sp&sale_count\n",
    "(exp2, prod2) = (0, 1) # exp_id, product_id\n",
    "# For each product cross exp_id, sum the sale prices and sale_count\n",
    "grouped_result = transformed.reduceByKey(lambda x,y: (x[sp]+y[sp], x[clks]+y[clks]))\n",
    "grouped_by_product = grouped_result.map(lambda x: ((x[ep][prod2]), (x[ep][exp2], x[spc][sp], x[spc][clks]))).groupByKey()\n",
    "\n",
    "numerator_sum = grouped_by_product.map(lambda x: calc_numerator(x)).reduce(add)\n",
    "denominator_sum = grouped_by_product.map(lambda x: calc_denominator(x)).reduce(add)\n",
    "effect = numerator_sum / denominator_sum\n",
    "print(numerator_sum, denominator_sum, effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:oauth2client.contrib.multistore_file:The oauth2client.contrib.multistore_file module has been deprecated and will be removed in the next release of oauth2client. Please migrate to multiprocess_file_storage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.direct_runner.DirectPipelineResult at 0x1089dad10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "\n",
    "def t_sum(values):\n",
    "    result = [0,0]\n",
    "    for v in values:\n",
    "        result[0] += v[0]\n",
    "        result[1] += v[1]\n",
    "    return (result[0], result[1])\n",
    "\n",
    "# Create a pipeline executing on a direct runner (local, non-cloud).\n",
    "# DirectPipelineRunner is the default runner, I'm setting it here to show how one\n",
    "# would change it to run on the Dataflow Service.\n",
    "pipeline_options = beam.utils.options.PipelineOptions(['--runner=DirectPipelineRunner'])\n",
    "p = beam.Pipeline(options=pipeline_options)\n",
    "\n",
    "parsed_input_rdd = (p\n",
    " | 'load records' >> beam.io.Read(beam.io.TextFileSource('sim_data_{0}_{1}.csv'.format(NUM_LE, NUM_HE)))\n",
    " | 'filter header' >> beam.Filter(lambda x: x[0] != '#')\n",
    " | 'split line' >> beam.Map(lambda x: convert_line(x.split(','))))\n",
    "transformed = (parsed_input_rdd\n",
    " | 'reshape' >> beam.Map((lambda x: ((x[exp], x[prod]), (x[price]*x[sale_count], x[sale_count])))))\n",
    "\n",
    "(sp, clks) = (0, 1) # sale price and sale_count\n",
    "(ep, spc) = (0, 1) # exp_id&product_id, sp&sale_count\n",
    "(exp2, prod2) = (0, 1) # exp_id, product_id\n",
    "\n",
    "# For each product cross exp_id, sum the sale prices and sale_count\n",
    "grouped_result = (transformed\n",
    " | 'combine per product/id' >> beam.CombinePerKey(t_sum))\n",
    "grouped_by_product = (grouped_result\n",
    " | 'keyByExpProduct' >> beam.Map(lambda x: ((x[ep][prod2]), (x[ep][exp2], x[spc][sp], x[spc][clks])))\n",
    " | 'group' >> beam.GroupByKey())\n",
    "\n",
    "numerator_sum = (grouped_by_product\n",
    " | 'MapForNum' >> beam.Map(lambda x: calc_numerator(x))\n",
    " | 'CombineNum' >> beam.CombineGlobally(sum))\n",
    "numerator_sum | 'save numerator' >> beam.io.Write(beam.io.TextFileSink('./numerator_sum'))\n",
    "\n",
    "denominator_sum = (grouped_by_product\n",
    " | 'MapForDenom' >> beam.Map(lambda x: calc_denominator(x))\n",
    " | 'CombineDenom' >> beam.CombineGlobally(sum))\n",
    "denominator_sum | 'save denominator' >> beam.io.Write(beam.io.TextFileSink('./denominator_sum'))\n",
    "p.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
